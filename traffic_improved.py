# -*- coding: utf-8 -*-
"""traffic_improved.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c_hcctoxowid8jsfsz85XkoJxdm1zwoh
"""

# Cell 1: Install required libraries
!pip install osmnx networkx numpy matplotlib

# Cell 2: Import libraries and set up basic environment
import osmnx as ox
import networkx as nx
import numpy as np
import matplotlib.pyplot as plt
import random
import time
from collections import deque, defaultdict
import heapq

# Set up environment - update settings directly instead of using config()
ox.settings.log_console = True
ox.settings.use_cache = False
print("Libraries imported and environment configured.")

# Cell 3: Extract road network from OpenStreetMap
def extract_road_network(place_name="Los Angeles, California, USA", network_type="drive"):
    """Extract road network from OpenStreetMap by place name"""
    print(f"Extracting road network for {place_name}...")
    graph = ox.graph_from_place(place_name, network_type=network_type)

    # Project to UTM for accurate distance calculations
    graph = ox.project_graph(graph)

    # Convert to undirected graph for community detection
    undirected_graph = nx.Graph(graph)

    print(f"Network extracted with {len(undirected_graph.nodes)} nodes and {len(undirected_graph.edges)} edges")
    return undirected_graph

# Extract a sample road network
G = extract_road_network(place_name="Manhattan, New York City, USA")

# Cell 4: Prepare graph by assigning weights
def assign_weights(G):
    """Assign weights to nodes and edges"""
    # Assign node weights based on degree centrality
    centrality = nx.degree_centrality(G)

    # Add node weights
    for node in G.nodes():
        G.nodes[node]['weight'] = centrality.get(node, 0.1)

    # Add edge weights based on length and simulated traffic
    for u, v, data in G.edges(data=True):
        # Use length as base weight or 1 if not available
        length = data.get('length', 1)

        # Simulate traffic density (random value between 1-100)
        traffic_density = np.random.randint(1, 100)

        # Calculate edge weight incorporating traffic
        edge_weight = length * (1 + traffic_density/100)

        # Store original and derived values
        G[u][v]['length'] = length
        G[u][v]['traffic_density'] = traffic_density
        G[u][v]['weight'] = edge_weight
        G[u][v]['base_weight'] = length  # Original length for comparison

    print("Graph prepared with node and edge weights")
    return G

# Prepare the graph with weights
G = assign_weights(G)

# Cell 5: Implement gravity-based community detection
def calculate_gravitational_force(G, node1, node2):
    """Calculate gravitational force between two nodes"""
    weight1 = G.nodes[node1]['weight']
    weight2 = G.nodes[node2]['weight']

    # Get edge data
    edge_data = G.get_edge_data(node1, node2, default={})
    traffic_density = edge_data.get('traffic_density', 1)
    length = edge_data.get('length', 1)

    # Calculate gravity (proportional to weights, inversely to distance)
    # Use traffic density as a multiplier
    gravity = (weight1 * weight2 * traffic_density) / length

    return gravity

def assign_nodes_to_communities(G, min_size=15, max_size=40):
    """
    Assign nodes to communities using gravity-based algorithm

    Parameters:
    - G: NetworkX graph
    - min_size: Minimum community size
    - max_size: Maximum community size

    Returns:
    - Dictionary mapping nodes to community IDs
    """
    # Start with all nodes unassigned
    unassigned_nodes = set(G.nodes())
    communities = {}
    community_id = 1

    while unassigned_nodes:
        # Choose seed node with highest degree
        seed = max(unassigned_nodes, key=lambda node: G.degree[node])

        # Adaptive community size based on seed importance
        seed_degree = G.degree[seed]
        max_degree = max(dict(G.degree()).values())
        community_size = int(max_size - (seed_degree / max_degree * (max_size - min_size)))

        # Initialize queue with seed
        queue = deque([seed])
        communities[seed] = community_id
        unassigned_nodes.remove(seed)
        current_size = 1

        # Grow community based on gravity
        while queue and current_size < community_size:
            current = queue.popleft()

            # Find neighbors and sort by gravitational force
            neighbors = list(G.neighbors(current))
            neighbors.sort(
                key=lambda neighbor: calculate_gravitational_force(G, current, neighbor)
                if neighbor in unassigned_nodes else -1,
                reverse=True
            )

            # Add highest gravity neighbors to community
            for neighbor in neighbors:
                if neighbor in unassigned_nodes:
                    communities[neighbor] = community_id
                    unassigned_nodes.remove(neighbor)
                    queue.append(neighbor)
                    current_size += 1

                    if current_size >= community_size:
                        break

        # Move to next community
        community_id += 1

    print(f"Created {community_id-1} communities using gravity-based detection")
    return communities

# Apply community detection
communities = assign_nodes_to_communities(G)

# Cell 6: Find bridges between communities and create community graph
def find_community_bridges(G, communities):
    """
    Find bridge edges between communities

    Parameters:
    - G: NetworkX graph
    - communities: Dictionary mapping nodes to communities

    Returns:
    - Set of bridge edges (u, v, data)
    """
    bridges = set()

    for u, v, data in G.edges(data=True):
        if communities.get(u) != communities.get(v):
            bridges.add((u, v))

    print(f"Found {len(bridges)} bridge edges between communities")
    return bridges

def create_community_graph(G, communities, bridges):
    """
    Create a community-level graph where nodes are communities

    Parameters:
    - G: Original graph
    - communities: Node to community mapping
    - bridges: Set of bridge edges between communities

    Returns:
    - NetworkX graph representing communities
    """
    # Create mapping from community ID to nodes
    community_nodes = defaultdict(list)
    for node, comm in communities.items():
        community_nodes[comm].append(node)

    # Create community graph
    community_graph = nx.Graph()

    # Add nodes (communities)
    for comm in community_nodes:
        # Calculate average node weight for the community
        avg_weight = np.mean([G.nodes[n]['weight'] for n in community_nodes[comm]])
        community_graph.add_node(comm, weight=avg_weight, size=len(community_nodes[comm]))

    # Add edges between communities
    for u, v in bridges:
        comm_u = communities[u]
        comm_v = communities[v]

        edge_data = G.get_edge_data(u, v)
        weight = edge_data['weight']

        # If edge already exists, use minimum weight
        if community_graph.has_edge(comm_u, comm_v):
            community_graph[comm_u][comm_v]['weight'] = min(
                community_graph[comm_u][comm_v]['weight'],
                weight
            )
        else:
            community_graph.add_edge(
                comm_u,
                comm_v,
                weight=weight,
                crossing_nodes=(u, v)
            )

    print(f"Created community graph with {len(community_graph.nodes)} nodes and {len(community_graph.edges)} edges")
    return community_graph

# Create community bridges and graph
bridges = find_community_bridges(G, communities)
community_graph = create_community_graph(G, communities, bridges)

# Cell 7: Implement multi-level Dijkstra for pathfinding
def multi_level_dijkstra(G, community_graph, communities, source, target):
    """
    Find shortest path using community structure

    Parameters:
    - G: Original graph
    - community_graph: Community-level graph
    - communities: Node to community mapping
    - source: Source node
    - target: Target node

    Returns:
    - Path length
    """
    # Get communities for source and target
    source_community = communities.get(source)
    target_community = communities.get(target)

    # Case 1: Source and target in same community
    if source_community == target_community:
        try:
            return nx.shortest_path_length(G, source, target, weight='weight')
        except nx.NetworkXNoPath:
            return float('inf')

    # Case 2: Different communities
    # Step 1: Find path between communities
    try:
        community_path = nx.shortest_path(
            community_graph,
            source=source_community,
            target=target_community,
            weight='weight'
        )
    except nx.NetworkXNoPath:
        return float('inf')

    # Step 2: Find entry/exit points for each community
    community_sequence = []
    for i in range(len(community_path)-1):
        current_comm = community_path[i]
        next_comm = community_path[i+1]

        # Get crossing nodes between communities
        if community_graph.has_edge(current_comm, next_comm):
            crossing = community_graph[current_comm][next_comm].get('crossing_nodes')
            if crossing:
                community_sequence.append(crossing)

    # Step 3: Calculate total path length
    total_length = 0

    # Find path from source to first border
    if community_sequence:
        first_exit = community_sequence[0][0]
        try:
            length = nx.shortest_path_length(G, source, first_exit, weight='weight')
            total_length += length
        except nx.NetworkXNoPath:
            return float('inf')

        # Add lengths between borders
        current_node = community_sequence[0][1]  # First entry to second community

        for i in range(1, len(community_sequence)):
            next_exit = community_sequence[i][0]
            try:
                length = nx.shortest_path_length(G, current_node, next_exit, weight='weight')
                total_length += length
            except nx.NetworkXNoPath:
                return float('inf')

            current_node = community_sequence[i][1]

        # Add length from last entry to target
        try:
            length = nx.shortest_path_length(G, current_node, target, weight='weight')
            total_length += length
        except nx.NetworkXNoPath:
            return float('inf')

    return total_length

# Cell 8: Optimized multi-level Dijkstra with border selection
def optimized_multi_level_dijkstra(G, community_graph, communities, source, target):
    """
    Optimized implementation with better border node selection

    Parameters:
    - G: Original graph
    - community_graph: Community-level graph
    - communities: Node to community mapping
    - source: Source node
    - target: Target node

    Returns:
    - Path length
    """
    source_community = communities.get(source)
    target_community = communities.get(target)

    # Same community case
    if source_community == target_community:
        try:
            return nx.shortest_path_length(G, source, target, weight='weight')
        except nx.NetworkXNoPath:
            return float('inf')

    # Find community-level path
    try:
        community_path = nx.shortest_path(
            community_graph,
            source=source_community,
            target=target_community,
            weight='weight'
        )
    except nx.NetworkXNoPath:
        return float('inf')

    # For each community pair, select the best border crossing
    current_node = source
    total_path_length = 0

    for i in range(len(community_path) - 1):
        current_community = community_path[i]
        next_community = community_path[i + 1]

        # Get nodes in current and next community
        current_community_nodes = [node for node, comm in communities.items()
                                 if comm == current_community]
        next_community_nodes = [node for node, comm in communities.items()
                              if comm == next_community]

        # Find reachable nodes from current node in current community
        try:
            distances = nx.single_source_dijkstra_path_length(
                G, current_node, weight='weight'
            )
        except nx.NetworkXNoPath:
            return float('inf')

        # Find best crossing
        best_crossing_cost = float('inf')
        best_exit = None
        best_entry = None

        for exit_node in current_community_nodes:
            if exit_node in distances:
                for entry_node in next_community_nodes:
                    if G.has_edge(exit_node, entry_node):
                        crossing_cost = (
                            distances[exit_node] +
                            G[exit_node][entry_node]['weight']
                        )
                        if crossing_cost < best_crossing_cost:
                            best_crossing_cost = crossing_cost
                            best_exit = exit_node
                            best_entry = entry_node

        if best_exit is None:
            return float('inf')

        # Add path length to best exit node
        total_path_length += distances[best_exit]

        # Add edge weight for crossing
        total_path_length += G[best_exit][best_entry]['weight']

        # Update current node to entry of next community
        current_node = best_entry

    # Add path from last community entry to target
    try:
        final_length = nx.shortest_path_length(
            G, current_node, target, weight='weight'
        )
        total_path_length += final_length
    except nx.NetworkXNoPath:
        return float('inf')

    return total_path_length

# Cell 9: Benchmark and evaluate performance
def benchmark_pathfinding(G, community_graph, communities, num_trials=100):
    """
    Benchmark standard Dijkstra vs. multi-level Dijkstra

    Parameters:
    - G: Original graph
    - community_graph: Community-level graph
    - communities: Node to community mapping
    - num_trials: Number of random trials
    """
    standard_times = []
    multilevel_times = []
    optimized_times = []

    standard_lengths = []
    multilevel_lengths = []
    optimized_lengths = []

    nodes = list(G.nodes())

    print(f"Running {num_trials} pathfinding trials...")
    for i in range(num_trials):
        # Random source and target
        source, target = random.sample(nodes, 2)

        # Standard Dijkstra
        start_time = time.time()
        try:
            standard_length = nx.shortest_path_length(G, source, target, weight='weight')
            standard_lengths.append(standard_length)
        except nx.NetworkXNoPath:
            standard_lengths.append(float('inf'))
        standard_time = time.time() - start_time
        standard_times.append(standard_time)

        # Multi-level Dijkstra
        start_time = time.time()
        multilevel_length = multi_level_dijkstra(G, community_graph, communities, source, target)
        multilevel_lengths.append(multilevel_length)
        multilevel_time = time.time() - start_time
        multilevel_times.append(multilevel_time)

        # Optimized Multi-level Dijkstra
        start_time = time.time()
        optimized_length = optimized_multi_level_dijkstra(G, community_graph, communities, source, target)
        optimized_lengths.append(optimized_length)
        optimized_time = time.time() - start_time
        optimized_times.append(optimized_time)

        if (i+1) % 10 == 0:
            print(f"Completed {i+1}/{num_trials} trials")

    # Calculate statistics
    avg_standard_time = np.mean(standard_times)
    avg_multilevel_time = np.mean(multilevel_times)
    avg_optimized_time = np.mean(optimized_times)

    # Calculate path length differences (only for paths that exist)
    valid_pairs_ml = [(s, m) for s, m in zip(standard_lengths, multilevel_lengths)
                      if s != float('inf') and m != float('inf')]
    valid_pairs_opt = [(s, o) for s, o in zip(standard_lengths, optimized_lengths)
                       if s != float('inf') and o != float('inf')]

    if valid_pairs_ml:
        std_valid_ml, ml_valid = zip(*valid_pairs_ml)
        avg_length_diff_ml = np.mean([(m - s) / s * 100 for s, m in zip(std_valid_ml, ml_valid)])
    else:
        avg_length_diff_ml = "N/A"

    if valid_pairs_opt:
        std_valid_opt, opt_valid = zip(*valid_pairs_opt)
        avg_length_diff_opt = np.mean([(o - s) / s * 100 for s, o in zip(std_valid_opt, opt_valid)])
    else:
        avg_length_diff_opt = "N/A"

    # Print results
    print("\n--- Benchmark Results ---")
    print(f"Standard Dijkstra Average Time: {avg_standard_time:.6f} s")
    print(f"Multi-level Dijkstra Average Time: {avg_multilevel_time:.6f} s")
    print(f"Optimized Multi-level Average Time: {avg_optimized_time:.6f} s")
    print(f"Speedup (Multi-level): {(avg_standard_time/avg_multilevel_time):.2f}x")
    print(f"Speedup (Optimized): {(avg_standard_time/avg_optimized_time):.2f}x")
    print(f"Path Length Increase (Multi-level): {avg_length_diff_ml}%")
    print(f"Path Length Increase (Optimized): {avg_length_diff_opt}%")

    return {
        'standard_time': avg_standard_time,
        'multilevel_time': avg_multilevel_time,
        'optimized_time': avg_optimized_time,
        'length_diff_ml': avg_length_diff_ml,
        'length_diff_opt': avg_length_diff_opt
    }

# Run benchmarks
benchmark_results = benchmark_pathfinding(G, community_graph, communities, num_trials=50)